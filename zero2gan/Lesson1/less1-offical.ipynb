{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.rand(50,4)*120\n",
    "w = torch.rand(1,4,requires_grad=True)\n",
    "b = torch.rand(1,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 38.1090,  90.0748,  90.8044,  18.3203],\n",
      "        [ 92.7394,  69.0846,  30.7332, 114.1033],\n",
      "        [ 73.7445,  39.2405, 119.3159,  90.3881],\n",
      "        [  8.8413,  19.1869,  14.4117, 110.3634],\n",
      "        [ 63.8684,  21.0068,  91.3061,  82.1154],\n",
      "        [ 76.3910,  48.7436,  63.3005,  52.8776],\n",
      "        [ 63.8104, 118.8608,  28.5205,  54.3462],\n",
      "        [ 97.0689,  14.8856,  95.1099,  10.0529],\n",
      "        [ 87.0210,   8.0755,  88.9936,  15.9382],\n",
      "        [ 35.5613, 103.3002, 104.5109,  11.6222],\n",
      "        [ 88.5500,  59.2552, 119.2599,  55.6100],\n",
      "        [107.6939,  86.7715,   4.3858, 101.8589],\n",
      "        [ 38.8858,   7.8425,  17.3244, 109.3412],\n",
      "        [ 84.2999,  86.2826, 102.3810,   1.1487],\n",
      "        [115.7478,  56.7921,  42.1461,  79.9841],\n",
      "        [ 55.5004,  27.8206, 117.5484,  37.1745],\n",
      "        [ 26.2843,  64.7244,  86.8639,  92.6581],\n",
      "        [ 30.8929,  49.4342,  73.3170,  87.0344],\n",
      "        [ 38.9572,  56.9641,  36.1822,  74.6300],\n",
      "        [111.2390,  74.3126,  91.8263,   6.6592],\n",
      "        [ 24.8574, 118.2647,  75.7673,  14.6153],\n",
      "        [110.1923,  20.8312,   1.6661,   6.9990],\n",
      "        [ 90.0678,  60.5374, 100.2447,  23.6210],\n",
      "        [110.8473, 107.5984, 116.5135,  58.3007],\n",
      "        [ 52.4863, 112.6320,   9.7437,  88.5924],\n",
      "        [ 46.3012,  14.5358,  59.2419,  75.2923],\n",
      "        [ 54.1487,  66.0041,   9.6621,  98.0136],\n",
      "        [ 42.2144,  40.3708,  90.3477,  17.1181],\n",
      "        [ 16.6764,  26.1135,   5.4651,  75.1820],\n",
      "        [ 27.9934, 108.9191,  50.6395,  36.4942],\n",
      "        [ 58.6697,  94.2101,   3.6760, 106.8371],\n",
      "        [ 63.9649,  34.6863,  82.4672,  11.7473],\n",
      "        [ 35.1571,  98.7212,  74.9190, 100.9136],\n",
      "        [ 61.4208,  88.4102,  94.7818,  55.4404],\n",
      "        [ 47.3818,  66.0599,  58.3904, 117.3101],\n",
      "        [ 85.6619,  31.9710,  77.0704,  29.0397],\n",
      "        [ 11.9096,  95.3340,  42.5072,  50.1593],\n",
      "        [ 79.1822,  43.4113,  24.8813,   1.9517],\n",
      "        [111.6541,  17.9614,  64.0358,   8.1599],\n",
      "        [118.6360,  44.3396,  15.2182,  41.4432],\n",
      "        [ 68.4112,  61.0255,  97.0821, 100.4080],\n",
      "        [103.6002,  71.3033,  15.0983,  32.1599],\n",
      "        [105.6982,   7.6371, 111.5433, 109.0484],\n",
      "        [115.5546, 101.3658,   7.0112,  35.5973],\n",
      "        [ 91.0512,  89.7635,  18.2925,  93.4216],\n",
      "        [ 81.9352,  57.7815,  10.7893,  43.7784],\n",
      "        [ 39.6031, 100.4147,  34.7936,   0.3883],\n",
      "        [108.3570,  90.7787,  90.8525, 118.2901],\n",
      "        [  1.1555,  35.3854,  12.7624, 113.2414],\n",
      "        [ 90.0535,  76.1479,  80.5294,   0.2945]]) tensor([[0.2934, 0.6977, 0.4142, 0.3941]], requires_grad=True) tensor([0.6000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(features,w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    return x@w.t() + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.rand(50,1,requires_grad=True)*120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(TensorDataset(features,labels),batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 26.2843,  64.7244,  86.8639,  92.6581],\n",
      "        [118.6360,  44.3396,  15.2182,  41.4432],\n",
      "        [105.6982,   7.6371, 111.5433, 109.0484],\n",
      "        [ 27.9934, 108.9191,  50.6395,  36.4942],\n",
      "        [111.6541,  17.9614,  64.0358,   8.1599],\n",
      "        [ 38.9572,  56.9641,  36.1822,  74.6300],\n",
      "        [ 55.5004,  27.8206, 117.5484,  37.1745],\n",
      "        [ 35.1571,  98.7212,  74.9190, 100.9136],\n",
      "        [ 63.9649,  34.6863,  82.4672,  11.7473],\n",
      "        [115.5546, 101.3658,   7.0112,  35.5973]]) tensor([[ 82.6320],\n",
      "        [ 46.9363],\n",
      "        [ 58.2107],\n",
      "        [118.6289],\n",
      "        [116.2744],\n",
      "        [ 14.1163],\n",
      "        [ 96.6851],\n",
      "        [116.5484],\n",
      "        [100.5326],\n",
      "        [ 60.4271]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "for xb,yb in train_dl:\n",
    "    print(xb,yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(preds,labels):\n",
    "    return torch.sum((preds - labels)**2) / labels.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1216.8040, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for xb,yb in train_dl:\n",
    "    print(mse(predict(xb),yb))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: tensor(2047.0511, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1672.8658, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1754.2574, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1256.1912, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(667.2474, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1595.9707, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(587.9731, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1247.2308, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1848.1205, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2129.0620, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2018.0305, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1272.8741, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1455.2590, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1520.7867, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1144.1022, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(161.0210, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1640.2734, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1372.1296, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2287.5122, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1948.0632, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1185.1877, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1909.3480, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(935.9662, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2008.5588, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1352.3821, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1895.4705, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1800.7906, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1255.7493, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(963.7803, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1515.6342, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1690.2904, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1194.0376, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1209.8223, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1933.7744, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1360.5981, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1560.3943, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1574.8574, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1728.2258, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1039.2839, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1558.3158, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1545.0919, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1196.4303, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1038.9219, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(446.5875, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(3161.1792, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1281.0298, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1532.8862, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1762.7311, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(901.0392, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1904.3591, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(663.7912, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1162.8732, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1189.1489, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2348.3345, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2062.0112, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1718.5326, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(582.8963, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1098.3092, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1703.5059, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2289.9529, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1748.9890, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(593.3267, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1900.8210, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1761.1041, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1373.6718, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1855.0232, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2023.6104, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1188.8793, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(965.6932, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1368.3544, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1021.6154, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(838.3358, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1278.9124, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2222.6003, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2055.7285, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(868.7346, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1649.5355, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1178.3529, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2577.5825, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1135.4377, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1899.3369, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1966.5980, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(677.1753, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1778.9957, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1073.3904, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(783.2731, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1837.3285, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1487.3463, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2099.6304, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1188.7345, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1037.9905, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1374.6331, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2645.3977, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1218.0422, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1107.8359, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(229.9297, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2111.6968, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1237.5013, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2676.4316, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1128.8940, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1710.3037, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1204.1117, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1242.3551, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1206.2738, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2012.5408, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1251.9398, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1442.4688, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1496.6130, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2319.5195, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(906.2042, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(868.0664, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1306.9042, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1079.9457, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1427.1346, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2700.2385, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1353.8838, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1535.4231, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2342.6614, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1049.2747, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1098.1614, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2648.5757, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1051.5767, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1698.7903, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(934.6313, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1099.3816, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1996.0582, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1321.3595, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1817.4342, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1175.2094, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1095.8204, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1402.5364, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1110.5603, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1739.9941, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1507.8389, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1615.2849, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1161.0795, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1063.0193, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2826.1836, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1090.8352, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1256.7268, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1043.9690, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1626.9041, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1985.5238, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1869.2357, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(895.2366, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1591.4602, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2246.4146, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(553.4546, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1581.8217, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1416.7224, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(730.5985, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1350.9557, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2153.3752, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2209.5713, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(953.5011, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1353.0306, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1679.0549, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1000.9683, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1523.0310, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1840.5593, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(928.7892, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1382.3962, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(777.9926, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2455.4487, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1870.3324, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1924.8630, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1580.4656, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(807.7970, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1380.0677, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1761.9664, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1411.7163, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1759.8445, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1146.1460, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1592.6920, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1517.5134, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: tensor(1103.9943, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1430.5782, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2523.8237, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(993.8133, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1339.3043, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1164.7378, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(714.8998, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1014.1268, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1941.5840, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2547.1860, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1488.1555, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(947.3998, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2882.2090, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(802.6046, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1281.0085, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1816.3480, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1168.8660, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1958.7340, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1399.6041, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1050.8372, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1110.1367, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1398.9070, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1040.8604, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1476.9409, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2377.7788, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1620.9417, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1988.6296, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1320.4861, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1297.8517, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1162.8054, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1366.0784, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1911.8115, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2225.8657, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(860.2342, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1044.0813, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2355.1704, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1285.9060, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1213.7605, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(740.7809, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1801.8444, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1126.7527, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1893.5316, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1210.8826, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1630.0853, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1537.5164, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2117.3086, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1127.8628, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1068.8887, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1741.1921, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1358.3385, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1129.5476, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1708.3330, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1140.0427, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1701.9203, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1745.3678, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1962.7744, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2262.3574, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(699.4377, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1018.9562, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1520.7709, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1348.9622, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(848.1696, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1299.3226, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(997.1063, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2914.9661, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(940.8616, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1525.4558, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1496.3092, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1069.0388, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2352.7173, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1588.1742, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2191.4045, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(935.8394, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1250.0436, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1433.4360, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(775.1185, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1158.1448, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1802.1143, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2161.1494, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1511.5286, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2738.8245, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1534.7584, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(632.8958, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1260.3362, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1222.0383, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1013.9564, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1295.2523, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1223.3713, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2199.9053, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1643.5580, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(712.0329, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1652.6169, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1406.4706, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(951.3929, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2667.5530, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1352.5134, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1532.2638, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1639.2484, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1179.1112, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1684.6160, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1968.6761, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(898.7689, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2327.4448, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(946.3039, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1235.9421, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1757.7812, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1825.1543, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(685.3002, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(926.0016, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2231.2798, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1768.2084, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1566.1061, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1186.1604, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1484.2146, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1387.6643, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1204.8086, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1763.2152, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2632.4578, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(816.1924, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(969.6097, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1936.0406, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1094.1732, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(990.5670, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1644.8961, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1741.6207, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(708.6671, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1707.0872, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1295.3499, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1774.4476, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1933.5094, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(725.2181, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1748.4402, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1591.1882, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2250.1531, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1147.1063, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1931.0120, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(337.5205, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2332.7859, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1469.2877, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1302.8282, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(632.4748, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1953.6846, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1842.5251, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1423.8046, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1527.8422, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1561.2119, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1162.9907, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1424.1429, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2484.6958, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(766.7223, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1636.5645, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1770.1201, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1400.2921, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1094.6609, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1498.5994, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2525.8579, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(787.0599, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1530.4199, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1450.9232, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1105.0659, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1339.5833, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2800.3398, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1243.6782, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1253.7224, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(769.8843, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1042.9760, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(938.8586, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: tensor(1244.4089, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1311.8118, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2858.8208, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1693.9401, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1953.8264, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(608.8199, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2069.9578, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1113.3176, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(956.4987, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(767.2760, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1176.2506, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1672.1140, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2814.3481, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1758.9854, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1505.8973, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1305.3732, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1627.0610, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1224.8226, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1867.0131, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(806.2298, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1348.7858, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1598.6292, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1778.9762, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1441.7732, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1828.3824, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1293.6907, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1313.0685, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1503.3978, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1201.0305, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(999.2064, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2770.4773, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1445.2815, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(990.8446, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1152.2167, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1435.4362, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1339.4408, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1467.2545, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2015.7291, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1495.7312, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1620.5612, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1379.7230, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1656.5807, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1264.3462, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1135.3483, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1298.6149, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1758.3926, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2006.5336, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1237.3391, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(618.4242, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(750.0877, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(849.3390, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2803.0359, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2382.7927, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1142.8191, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1242.6382, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2507.6147, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1195.3597, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1299.5386, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(921.3146, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1642.8043, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1480.8464, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1441.2565, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1893.8724, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1544.0525, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1329.7517, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1873.3512, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1163.9458, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1492.9252, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(561.6548, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1558.1149, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1866.9988, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1827.0781, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1600.5916, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2012.0605, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2184.1504, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(854.0466, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1137.7551, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1199.3103, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1311.0875, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(940.3123, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1912.3014, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1128.6124, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2111.7700, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1419.9128, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2180.1572, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1021.7170, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1269.9333, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1522.4395, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1172.2424, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1193.9399, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(907.0323, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1243.9376, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2887.4580, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1298.2993, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1290.3567, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1847.9109, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2278.4612, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(680.4465, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1149.7246, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1566.4360, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1403.1326, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1495.7971, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1786.9658, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1204.6700, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1613.5238, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1089.3728, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1044.6448, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2435.0464, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(729.0605, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1286.1165, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2170.1948, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1929.2412, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1298.9675, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1980.6731, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(937.6019, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2339.2661, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1109.7777, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1010.1593, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1254.6743, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1279.9850, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1530.2522, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2324.0969, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1049.2902, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2431.6060, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(829.5916, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1474.0533, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1408.0635, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1275.7102, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1411.9261, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1168.5045, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1706.8304, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1389.4137, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1722.7844, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1523.8053, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1150.7206, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(597.0748, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2936.1067, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1176.7255, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2311.8958, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1427.2095, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1445.9641, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(856.2474, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1335.3927, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1062.1908, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1476.0662, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1638.3910, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(2279.1206, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(943.3669, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1809.2008, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1657.9006, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1946.4929, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(1080.1660, grad_fn=<DivBackward0>)\n",
      "Current loss: tensor(917.3430, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,100):\n",
    "    for xb,yb in train_dl:\n",
    "        loss = mse(predict(xb),yb)\n",
    "        print(\"Current loss:\", loss)\n",
    "        loss.backward(retain_graph=True)\n",
    "        with torch.no_grad():\n",
    "            w -= w.grad*(1e-6 + 0.33e-6)\n",
    "            b -= b.grad*(1e-6 + 0.33e-6)\n",
    "            w.grad.zero_()\n",
    "            b.grad.zero_()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1608, 0.3106, 0.2730, 0.2446]], requires_grad=True)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6272], requires_grad=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1473.4438, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(predict(features),labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 71.1467],\n",
       "        [ 73.7750],\n",
       "        [ 74.8082],\n",
       "        [ 38.0850],\n",
       "        [ 56.9486],\n",
       "        [ 57.3658],\n",
       "        [ 79.4585],\n",
       "        [ 42.5002],\n",
       "        [ 38.2386],\n",
       "        [ 78.6963],\n",
       "        [ 77.5767],\n",
       "        [ 74.0891],\n",
       "        [ 36.4943],\n",
       "        [ 73.1126],\n",
       "        [ 65.7903],\n",
       "        [ 55.6153],\n",
       "        [ 74.0700],\n",
       "        [ 63.1083],\n",
       "        [ 55.4947],\n",
       "        [ 69.0890],\n",
       "        [ 77.9949],\n",
       "        [ 23.0145],\n",
       "        [ 66.5776],\n",
       "        [101.4803],\n",
       "        [ 78.5243],\n",
       "        [ 42.9344],\n",
       "        [ 59.7977],\n",
       "        [ 48.8378],\n",
       "        [ 32.0090],\n",
       "        [ 72.8252],\n",
       "        [ 73.4272],\n",
       "        [ 45.3590],\n",
       "        [ 89.1609],\n",
       "        [ 81.9410],\n",
       "        [ 75.3084],\n",
       "        [ 48.8374],\n",
       "        [ 66.1421],\n",
       "        [ 34.5902],\n",
       "        [ 37.3489],\n",
       "        [ 45.3720],\n",
       "        [ 80.8592],\n",
       "        [ 53.8935],\n",
       "        [ 66.0559],\n",
       "        [ 67.3999],\n",
       "        [ 75.2827],\n",
       "        [ 47.1565],\n",
       "        [ 58.3038],\n",
       "        [100.6986],\n",
       "        [ 44.8285],\n",
       "        [ 63.6141]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
